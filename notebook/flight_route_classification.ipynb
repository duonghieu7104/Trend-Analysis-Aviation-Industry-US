{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0ea879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, isnan, count, mean, stddev, sum\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af58c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FlightRouteClassification\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97201394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: C:\\Users\\ADMIN\\.cache\\kagglehub\\datasets\\bhavikjikadara\\us-airline-flight-routes-and-fares-1993-2024\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"bhavikjikadara/us-airline-flight-routes-and-fares-1993-2024\")\n",
    "print(f\"Dataset downloaded to: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c5a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .option(\"quote\", '\"')           # rất quan trọng: nhận diện text trong ngoặc kép\n",
    "    .option(\"escape\", '\"')          # escape ký tự \"\n",
    "    .option(\"multiLine\", \"true\")    # xử lý text có xuống dòng\n",
    "    .option(\"mode\", \"PERMISSIVE\")   # không drop dòng lỗi\n",
    "    .option(\"nullValue\", \"\")\n",
    "    .option(\"nanValue\", \"NaN\")\n",
    "    .option(\"emptyValue\", \"\")\n",
    "    .csv(f\"{path}/*.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4777eb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tbl: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- citymarketid_1: integer (nullable = true)\n",
      " |-- citymarketid_2: integer (nullable = true)\n",
      " |-- city1: string (nullable = true)\n",
      " |-- city2: string (nullable = true)\n",
      " |-- airportid_1: integer (nullable = true)\n",
      " |-- airportid_2: integer (nullable = true)\n",
      " |-- airport_1: string (nullable = true)\n",
      " |-- airport_2: string (nullable = true)\n",
      " |-- nsmiles: integer (nullable = true)\n",
      " |-- passengers: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- carrier_lg: string (nullable = true)\n",
      " |-- large_ms: double (nullable = true)\n",
      " |-- fare_lg: double (nullable = true)\n",
      " |-- carrier_low: string (nullable = true)\n",
      " |-- lf_ms: double (nullable = true)\n",
      " |-- fare_low: double (nullable = true)\n",
      " |-- Geocoded_City1: string (nullable = true)\n",
      " |-- Geocoded_City2: string (nullable = true)\n",
      " |-- tbl1apk: string (nullable = true)\n",
      "\n",
      "\n",
      "Số dòng: 245955\n",
      "Số cột: 23\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "print(f\"\\nSố dòng: {df.count()}\")\n",
    "print(f\"Số cột: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7f726b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+--------------+--------------+--------------------+--------------------+-----------+-----------+---------+---------+-------+----------+------+----------+--------+-------+-----------+------+--------+--------------+--------------+--------------------+\n",
      "|    tbl|Year|quarter|citymarketid_1|citymarketid_2|               city1|               city2|airportid_1|airportid_2|airport_1|airport_2|nsmiles|passengers|  fare|carrier_lg|large_ms|fare_lg|carrier_low| lf_ms|fare_low|Geocoded_City1|Geocoded_City2|             tbl1apk|\n",
      "+-------+----+-------+--------------+--------------+--------------------+--------------------+-----------+-----------+---------+---------+-------+----------+------+----------+--------+-------+-----------+------+--------+--------------+--------------+--------------------+\n",
      "|Table1a|2021|      3|         30135|         33195|Allentown/Bethleh...|Tampa, FL (Metrop...|      10135|      14112|      ABE|      PIE|    970|       180| 81.43|        G4|     1.0|  81.43|         G4|   1.0|   81.43|          NULL|          NULL|202131013514112AB...|\n",
      "|Table1a|2021|      3|         30135|         33195|Allentown/Bethleh...|Tampa, FL (Metrop...|      10135|      15304|      ABE|      TPA|    970|        19|208.93|        DL|  0.4659| 219.98|         UA|0.1193|  154.11|          NULL|          NULL|202131013515304AB...|\n",
      "|Table1a|2021|      3|         30140|         30194|     Albuquerque, NM|Dallas/Fort Worth...|      10140|      11259|      ABQ|      DAL|    580|       204|184.56|        WN|  0.9968| 184.44|         WN|0.9968|  184.44|          NULL|          NULL|202131014011259AB...|\n",
      "|Table1a|2021|      3|         30140|         30194|     Albuquerque, NM|Dallas/Fort Worth...|      10140|      11298|      ABQ|      DFW|    580|       264|182.64|        AA|  0.9774| 183.09|         AA|0.9774|  183.09|          NULL|          NULL|202131014011298AB...|\n",
      "|Table1a|2021|      3|         30140|         30466|     Albuquerque, NM|         Phoenix, AZ|      10140|      14107|      ABQ|      PHX|    328|       398|177.11|        WN|  0.6061| 184.49|         AA|0.3939|  165.77|          NULL|          NULL|202131014014107AB...|\n",
      "+-------+----+-------+--------------+--------------+--------------------+--------------------+-----------+-----------+---------+---------+-------+----------+------+----------+--------+-------+-----------+------+--------+--------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e0cadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------+--------------+--------------+-----+-----+-----------+-----------+---------+---------+-------+----------+----+----------+--------+-------+-----------+-----+--------+--------------+--------------+-------+\n",
      "|tbl|Year|quarter|citymarketid_1|citymarketid_2|city1|city2|airportid_1|airportid_2|airport_1|airport_2|nsmiles|passengers|fare|carrier_lg|large_ms|fare_lg|carrier_low|lf_ms|fare_low|Geocoded_City1|Geocoded_City2|tbl1apk|\n",
      "+---+----+-------+--------------+--------------+-----+-----+-----------+-----------+---------+---------+-------+----------+----+----------+--------+-------+-----------+-----+--------+--------------+--------------+-------+\n",
      "|  0|   0|      0|             0|             0|    0|    0|          0|          0|        0|        0|      0|         0|   0|      1540|    1540|   1540|       1612| 1612|    1612|         39206|         39206|      0|\n",
      "+---+----+-------+--------------+--------------+-----+-----+-----------+-----------+---------+---------+-------+----------+----+----------+--------+-------+-----------+-----+--------+--------------+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2320472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị thiếu theo cột:\n",
      "+--------------+-------------+------------------+\n",
      "|Column        |Missing_Count|Percent           |\n",
      "+--------------+-------------+------------------+\n",
      "|Geocoded_City2|39206        |15.940314285133459|\n",
      "|Geocoded_City1|39206        |15.940314285133459|\n",
      "|fare_low      |1612         |0.6554044439023399|\n",
      "|carrier_low   |1612         |0.6554044439023399|\n",
      "|lf_ms         |1612         |0.6554044439023399|\n",
      "|large_ms      |1540         |0.626130796283873 |\n",
      "|fare_lg       |1540         |0.626130796283873 |\n",
      "|carrier_lg    |1540         |0.626130796283873 |\n",
      "+--------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== 1. DATA CLEANING ====================\n",
    "# Kiểm tra missing values\n",
    "print(\"Giá trị thiếu theo cột:\")\n",
    "from pyspark.sql.functions import col as spark_col, when, sum as spark_sum, lit\n",
    "\n",
    "# Tổng số dòng\n",
    "_total = df.count()\n",
    "\n",
    "# Tính số lượng thiếu cho từng cột bằng một lần quét\n",
    "missing_row = df.select([\n",
    "    spark_sum(when(spark_col(c).isNull(), 1).otherwise(0)).alias(c) for c in df.columns\n",
    "]).collect()[0]\n",
    "\n",
    "# Tạo DataFrame hiển thị Missing_Count và Percent\n",
    "missing_records = []\n",
    "for c in df.columns:\n",
    "    miss = int(missing_row[c]) if missing_row[c] is not None else 0\n",
    "    if miss > 0:\n",
    "        pct = (miss / _total * 100) if _total > 0 else 0\n",
    "        missing_records.append((c, miss, float(pct)))\n",
    "\n",
    "missing_df = spark.createDataFrame(missing_records, [\"Column\", \"Missing_Count\", \"Percent\"]) \\\n",
    "    .orderBy(spark_col(\"Missing_Count\").desc())\n",
    "\n",
    "if missing_df.count() > 0:\n",
    "    missing_df.show(truncate=False)\n",
    "else:\n",
    "    print(\"Không có giá trị thiếu nào trong DataFrame!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d5ca755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số dòng trước khi loại null: 245955\n",
      "Số dòng sau khi loại null: 244343\n",
      "  - large_ms không hợp lệ: 0\n",
      "  - lf_ms không hợp lệ: 0\n",
      "\n",
      " Dữ liệu sau khi làm sạch: (237985, 23)\n"
     ]
    }
   ],
   "source": [
    "# Loại bỏ các hàng có giá trị null trong các cột quan trọng\n",
    "cols_to_check = [\n",
    "    \"lf_ms\", \"carrier_low\", \"fare_low\",\n",
    "    \"large_ms\", \"fare_lg\", \"carrier_lg\"\n",
    "]\n",
    "\n",
    "# Loại bỏ các hàng có giá trị null trong các cột này\n",
    "df_clean = df.dropna(subset=cols_to_check)\n",
    "\n",
    "print(\"Số dòng trước khi loại null:\", df.count())\n",
    "print(\"Số dòng sau khi loại null:\", df_clean.count())\n",
    "\n",
    "# 4 Loại bỏ trùng lặp\n",
    "initial_count = df_clean.count()\n",
    "df_clean = df_clean.dropDuplicates()\n",
    "removed = initial_count - df_clean.count()\n",
    "\n",
    "# Market share trong [0,100]\n",
    "for c in ['large_ms', 'lf_ms']:\n",
    "    if c in df_clean.columns:\n",
    "        invalid = df_clean.filter((col(c) < 0) | (col(c) > 1)).count()\n",
    "        print(f\"  - {c} không hợp lệ: {invalid}\")\n",
    "        df_clean = df_clean.filter((col(c) >= 0) & (col(c) <= 1))\n",
    "\n",
    "# passengers & fare > 0\n",
    "for c in ['passengers', 'fare']:\n",
    "    if c in df_clean.columns:\n",
    "        df_clean = df_clean.filter(col(c) > 0)\n",
    "\n",
    "# 7️ Kết quả\n",
    "df_clean = df_clean\n",
    "\n",
    "rows_final = df_clean.count()\n",
    "cols_final = len(df_clean.columns)\n",
    "print(f\"\\n Dữ liệu sau khi làm sạch: ({rows_final}, {cols_final})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db82536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BƯỚC 2: PHÂN TÍCH KHÁM PHÁ DỮ LIỆU (EDA)\n",
      "================================================================================\n",
      "\n",
      "Thống kê mô tả các biến số:\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Column                    Count       Mean        Std        Min         Q1     Median         Q3        Max\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Year                     237985    2008.64       8.66       1993       2001       2009       2016       2024\n",
      "quarter                  237985       2.48       1.12          1          1          2          3          4\n",
      "citymarketid_1           237985   31556.83    1094.45      30135      30721      31295      32467      35412\n",
      "citymarketid_2           237985   32175.24    1232.17      30189      30977      32211      33192      35628\n",
      "airportid_1              237985   12438.23    1430.69      10135      11193      12266      13487      16440\n",
      "airportid_2              237985   13239.73    1425.33      10466      12197      13303      14679      15919\n",
      "nsmiles                  237985    1189.61     699.24        109        632       1021       1733       2724\n",
      "passengers               237985     309.50     516.89          1         26        122        353       8301\n",
      "fare                     237985     216.88      74.31      50.41      164.9     208.92     261.33    1161.22\n",
      "large_ms                 237985       0.66       0.22        0.1       0.48       0.65       0.86        1.0\n",
      "fare_lg                  237985     217.17      79.29      50.41     161.79     207.72     262.34    1501.42\n",
      "lf_ms                    237985       0.44       0.33       0.01       0.15     0.3474     0.7273        1.0\n",
      "fare_low                 237985     188.66      67.29       50.1     140.06      181.1     228.49    1269.78\n"
     ]
    }
   ],
   "source": [
    "# ==================== 2. EXPLORATORY DATA ANALYSIS ====================\n",
    "from pyspark.sql.types import IntegerType, LongType, FloatType, DoubleType\n",
    "from pyspark.sql.functions import col, count, mean, stddev, min, max, percentile_approx\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BƯỚC 2: PHÂN TÍCH KHÁM PHÁ DỮ LIỆU (EDA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Lấy các cột số\n",
    "numeric_cols = [field.name for field in df_clean.schema.fields if field.dataType in [IntegerType(), LongType(), FloatType(), DoubleType()]]\n",
    "\n",
    "# Header đẹp\n",
    "header = f\"{'Column':<20} {'Count':>10} {'Mean':>10} {'Std':>10} {'Min':>10} {'Q1':>10} {'Median':>10} {'Q3':>10} {'Max':>10}\"\n",
    "print(\"\\nThống kê mô tả các biến số:\")\n",
    "print(\"-\" * len(header))\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "# Thống kê từng cột\n",
    "for col_name in numeric_cols:\n",
    "    if col_name in df_clean.columns:\n",
    "        stats = df_clean.select(\n",
    "            count(col(col_name)).alias(\"count\"),\n",
    "            mean(col(col_name)).alias(\"mean\"),\n",
    "            stddev(col(col_name)).alias(\"std\"),\n",
    "            min(col(col_name)).alias(\"min\"),\n",
    "            max(col(col_name)).alias(\"max\"),\n",
    "            percentile_approx(col(col_name), 0.25).alias(\"q1\"),\n",
    "            percentile_approx(col(col_name), 0.5).alias(\"median\"),\n",
    "            percentile_approx(col(col_name), 0.75).alias(\"q3\")\n",
    "        ).collect()[0]\n",
    "\n",
    "        print(f\"{col_name:<20} \"\n",
    "              f\"{stats['count']:>10} \"\n",
    "              f\"{stats['mean']:>10.2f} \"\n",
    "              f\"{stats['std']:>10.2f} \"\n",
    "              f\"{stats['min']:>10} \"\n",
    "              f\"{stats['q1']:>10} \"\n",
    "              f\"{stats['median']:>10} \"\n",
    "              f\"{stats['q3']:>10} \"\n",
    "              f\"{stats['max']:>10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b794c780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BƯỚC 1: TÍNH TOÁN ĐIỂM SỐ TIỀM NĂNG\n",
      "==================================================\n",
      "\n",
      "Phân bố tiềm năng tuyến bay:\n",
      "+---------------+------+\n",
      "|potential_level| count|\n",
      "+---------------+------+\n",
      "|            Cao| 27047|\n",
      "|           Thấp|120694|\n",
      "|     Trung bình| 90244|\n",
      "+---------------+------+\n",
      "\n",
      "\n",
      "Tỷ lệ phần trăm:\n",
      "+---------------+------+----------+\n",
      "|potential_level| count|percentage|\n",
      "+---------------+------+----------+\n",
      "|            Cao| 27047|    11.365|\n",
      "|           Thấp|120694|    50.715|\n",
      "|     Trung bình| 90244|     37.92|\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lit, when, round\n",
    "\n",
    "# BƯỚC 1: TÍNH TOÁN ĐIỂM SỐ TIỀM NĂNG (POTENTIAL SCORE)\n",
    "print(\"BƯỚC 1: TÍNH TOÁN ĐIỂM SỐ TIỀM NĂNG\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Tạo bản sao dữ liệu để xử lý\n",
    "df_potential = df_clean\n",
    "\n",
    "# 1. Chuẩn hóa các chỉ số (0-1 scale)\n",
    "metrics = ['passengers', 'fare', 'nsmiles', 'large_ms', 'lf_ms']\n",
    "\n",
    "# Tính toán min và max để chuẩn hóa\n",
    "min_max_stats = {}\n",
    "for metric in metrics:\n",
    "    if metric in df_potential.columns:\n",
    "        stats = df_potential.select(\n",
    "            F.min(col(metric)).alias(\"min_val\"),\n",
    "            F.max(col(metric)).alias(\"max_val\")\n",
    "        ).collect()[0]\n",
    "        min_max_stats[metric] = {\n",
    "            'min': stats['min_val'],\n",
    "            'max': stats['max_val']\n",
    "        }\n",
    "\n",
    "# Chuẩn hóa từng số liệu\n",
    "for metric in metrics:\n",
    "    if metric in df_potential.columns and metric in min_max_stats:\n",
    "        min_val = min_max_stats[metric]['min']\n",
    "        max_val = min_max_stats[metric]['max']\n",
    "        if max_val != min_val:\n",
    "            df_potential = df_potential.withColumn(\n",
    "                f'{metric}_normalized',\n",
    "                (col(metric) - lit(min_val)) / (lit(max_val) - lit(min_val))\n",
    "            )\n",
    "        else:\n",
    "            df_potential = df_potential.withColumn(f'{metric}_normalized', lit(0.0))\n",
    "\n",
    "# 2. Tính điểm số tiềm năng dựa trên trọng số\n",
    "weights = {\n",
    "    'passengers_normalized': 0.25,\n",
    "    'fare_normalized': 0.2,\n",
    "    'nsmiles_normalized': 0.25,\n",
    "    'large_ms_normalized': 0.15,\n",
    "    'lf_ms_normalized': 0.15\n",
    "}\n",
    "\n",
    "potential_score_expr = lit(0.0)\n",
    "for metric, weight in weights.items():\n",
    "    if metric in df_potential.columns:\n",
    "        potential_score_expr = potential_score_expr + (col(metric) * weight)\n",
    "\n",
    "df_potential = df_potential.withColumn('potential_score', potential_score_expr)\n",
    "\n",
    "# 3. Phân loại theo điểm số tiềm năng\n",
    "df_potential = df_potential.withColumn(\n",
    "    'potential_level',\n",
    "    when(col('potential_score') > 0.4, 'Cao')\n",
    "    .when(col('potential_score') >= 0.3, 'Trung bình')\n",
    "    .otherwise('Thấp')\n",
    ")\n",
    "\n",
    "# 4. Thống kê phân bố\n",
    "print(\"\\nPhân bố tiềm năng tuyến bay:\")\n",
    "potential_dist = df_potential.groupBy('potential_level').count().orderBy('potential_level')\n",
    "potential_dist.show()\n",
    "\n",
    "# Tính tỷ lệ phần trăm\n",
    "total_count = df_potential.count()\n",
    "potential_percentages = df_potential.groupBy('potential_level').count() \\\n",
    "    .withColumn('percentage', round(col('count') / lit(total_count) * 100, 3)) \\\n",
    "    .orderBy('potential_level')\n",
    "\n",
    "print(\"\\nTỷ lệ phần trăm:\")\n",
    "potential_percentages.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5b9fe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thống kê mô tả theo nhóm tiềm năng:\n",
      "+---------------+--------------+--------+-----------+------------+---------+\n",
      "|potential_level|avg_passengers|avg_fare|avg_nsmiles|avg_large_ms|avg_lf_ms|\n",
      "+---------------+--------------+--------+-----------+------------+---------+\n",
      "|            Cao|       290.126| 266.536|   1906.513|       0.816|    0.743|\n",
      "|           Thấp|       329.452| 199.544|     905.14|        0.59|    0.273|\n",
      "|     Trung bình|       288.611| 225.185|   1355.191|       0.707|    0.571|\n",
      "+---------------+--------------+--------+-----------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Thống kê mô tả theo từng nhóm tiềm năng\n",
    "print(\"\\nThống kê mô tả theo nhóm tiềm năng:\")\n",
    "potential_stats = df_potential.groupBy('potential_level') \\\n",
    "    .agg(\n",
    "        round(mean('passengers'), 3).alias('avg_passengers'),\n",
    "        round(mean('fare'), 3).alias('avg_fare'),\n",
    "        round(mean('nsmiles'), 3).alias('avg_nsmiles'),\n",
    "        round(mean('large_ms'), 3).alias('avg_large_ms'),\n",
    "        round(mean('lf_ms'), 3).alias('avg_lf_ms')\n",
    "    ).orderBy('potential_level')\n",
    "potential_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b6509ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BƯỚC 2: PHÂN TÍCH XU HƯỚNG TĂNG TRƯỞNG\n",
      "==================================================\n",
      "\n",
      "Phân bố tiềm năng sau khi cải tiến:\n",
      "+------------------------+------+\n",
      "|potential_level_enhanced| count|\n",
      "+------------------------+------+\n",
      "|                     Cao| 12437|\n",
      "|                    Thấp|151411|\n",
      "|              Trung bình| 74137|\n",
      "+------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import first, last, col, lit, when\n",
    "\n",
    "# BƯỚC 2: PHÂN TÍCH XU HƯỚNG TĂNG TRƯỞNG\n",
    "print(\"\\nBƯỚC 2: PHÂN TÍCH XU HƯỚNG TĂNG TRƯỞNG\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Tạo cửa sổ phân vùng theo tuyến bay (city1, city2) và sắp xếp theo Year\n",
    "window_spec = Window.partitionBy('city1', 'city2').orderBy('Year') \\\n",
    "                   .rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "\n",
    "# Tính giá trị đầu và cuối cho mỗi tuyến bay\n",
    "df_with_growth = df_potential.withColumn(\n",
    "    'first_passengers', first('passengers').over(window_spec)\n",
    ").withColumn(\n",
    "    'last_passengers', last('passengers').over(window_spec)\n",
    ").withColumn(\n",
    "    'first_fare', first('fare').over(window_spec)\n",
    ").withColumn(\n",
    "    'last_fare', last('fare').over(window_spec)\n",
    ")\n",
    "\n",
    "# Tính tỷ lệ tăng trưởng\n",
    "df_with_growth = df_with_growth.withColumn(\n",
    "    'passenger_growth',\n",
    "    when(col('first_passengers') > 0,\n",
    "         (col('last_passengers') - col('first_passengers')) / col('first_passengers'))\n",
    "    .otherwise(0)\n",
    ").withColumn(\n",
    "    'fare_growth',\n",
    "    when(col('first_fare') > 0,\n",
    "         (col('last_fare') - col('first_fare')) / col('first_fare'))\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# Tính điểm tăng trưởng kết hợp (hành khách 70%, giá vé 30%)\n",
    "df_with_growth = df_with_growth.withColumn(\n",
    "    'growth_trend',\n",
    "    0.7 * col('passenger_growth') + 0.3 * col('fare_growth')\n",
    ")\n",
    "\n",
    "# Tự nhiên hóa xu hướng tăng trưởng (chuẩn hóa 0-1)\n",
    "growth_stats = df_with_growth.select(\n",
    "    F.min('growth_trend').alias('min_growth'),\n",
    "    F.max('growth_trend').alias('max_growth')\n",
    ").collect()[0]\n",
    "\n",
    "min_growth = growth_stats['min_growth']\n",
    "max_growth = growth_stats['max_growth']\n",
    "\n",
    "if max_growth != min_growth:\n",
    "    df_with_growth = df_with_growth.withColumn(\n",
    "        'growth_trend_normalized',\n",
    "        (col('growth_trend') - lit(min_growth)) / (lit(max_growth) - lit(min_growth))\n",
    "    )\n",
    "else:\n",
    "    df_with_growth = df_with_growth.withColumn('growth_trend_normalized', lit(0.0))\n",
    "\n",
    "# Cập nhật điểm số tiềm năng với xu hướng tăng trưởng (trọng số 10%)\n",
    "df_potential = df_with_growth.withColumn(\n",
    "    'potential_score_enhanced',\n",
    "    col('potential_score') * 0.9 + col('growth_trend_normalized') * 0.1\n",
    ")\n",
    "\n",
    "# Phân loại lại theo điểm số cải tiến\n",
    "df_potential = df_potential.withColumn(\n",
    "    'potential_level_enhanced',\n",
    "    when(col('potential_score_enhanced') > 0.4, 'Cao')\n",
    "    .when(col('potential_score_enhanced') >= 0.3, 'Trung bình')\n",
    "    .otherwise('Thấp')\n",
    ")\n",
    "\n",
    "# Hiển thị phân bố kết quả\n",
    "print(\"\\nPhân bố tiềm năng sau khi cải tiến:\")\n",
    "enhanced_dist = df_potential.groupBy('potential_level_enhanced').count().orderBy('potential_level_enhanced')\n",
    "enhanced_dist.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aead1ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BƯỚC 3: HUẤN LUYỆN MÔ HÌNH MACHINE LEARNING\n",
      "==================================================\n",
      "Kích thước dữ liệu:\n",
      "  - Train: 190573 mẫu\n",
      "  - Test: 47412 mẫu\n",
      "  - Số đặc trưng: 8\n"
     ]
    }
   ],
   "source": [
    "# BƯỚC 3: HUẤN LUYỆN MÔ HÌNH MACHINE LEARNING\n",
    "\n",
    "print(\"\\nBƯỚC 3: HUẤN LUYỆN MÔ HÌNH MACHINE LEARNING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Chuẩn bị các đặc trưng \n",
    "features_ml = ['passengers', 'fare', 'nsmiles', 'large_ms', 'lf_ms', 'fare_lg', 'fare_low', 'growth_trend']\n",
    "\n",
    "# Tạo feature vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=features_ml,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# String indexer for target variable\n",
    "label_indexer = StringIndexer(\n",
    "    inputCol=\"potential_level_enhanced\",\n",
    "    outputCol=\"label\"\n",
    ")\n",
    "# Create pipeline for feature preparation\n",
    "feature_pipeline = Pipeline(stages=[assembler, label_indexer])\n",
    "df_ml = feature_pipeline.fit(df_potential).transform(df_potential)\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Kích thước dữ liệu:\")\n",
    "print(f\"  - Train: {train_data.count()} mẫu\")\n",
    "print(f\"  - Test: {test_data.count()} mẫu\")\n",
    "print(f\"  - Số đặc trưng: {len(features_ml)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f843f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đánh giá mô hình\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def evaluate_model(predictions):\n",
    "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    evaluator_pre = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    evaluator_rec = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    accuracy = evaluator_acc.evaluate(predictions)\n",
    "    precision = evaluator_pre.evaluate(predictions)\n",
    "    recall = evaluator_rec.evaluate(predictions)\n",
    "    f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "    print(f\"  - Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"  - Precision: {precision:.4f}\")\n",
    "    print(f\"  - Recall   : {recall:.4f}\")\n",
    "    print(f\"  - F1-Score : {f1:.4f}\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee5966",
   "metadata": {},
   "source": [
    "### Huấn luyện mô hình `RANDOM FOREST CLASSIFIER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58d74ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HUẤN LUYỆN MÔ HÌNH: Random Forest\n",
      "------------------------------------------------------------\n",
      "Kết quả đánh giá Random Forest:\n",
      "  - Accuracy : 0.8924\n",
      "  - Precision: 0.8946\n",
      "  - Recall   : 0.8924\n",
      "  - F1-Score : 0.8925\n"
     ]
    }
   ],
   "source": [
    "# 1️ RANDOM FOREST\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "print(\"\\n HUẤN LUYỆN MÔ HÌNH: Random Forest\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    numTrees=20,\n",
    "    maxDepth=5,\n",
    "    seed=42)\n",
    "rf_model = rf.fit(train_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "print(\"Kết quả đánh giá Random Forest:\")\n",
    "rf_accuracy = evaluate_model(rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad85a5",
   "metadata": {},
   "source": [
    "### Huấn luyện mô hình `LOGISTIC REGRESSION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "215b8143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HUẤN LUYỆN MÔ HÌNH: Logistic Regression\n",
      "------------------------------------------------------------\n",
      "Kết quả đánh giá Logistic Regression:\n",
      "  - Accuracy : 0.9421\n",
      "  - Precision: 0.9451\n",
      "  - Recall   : 0.9421\n",
      "  - F1-Score : 0.9365\n"
     ]
    }
   ],
   "source": [
    "# 2 LOGISTIC REGRESSION\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "print(\"\\n HUẤN LUYỆN MÔ HÌNH: Logistic Regression\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Chỉ có L2 regularization\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    maxIter=100, \n",
    "    regParam=0.01)\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "print(\"Kết quả đánh giá Logistic Regression:\")\n",
    "lr_accuracy = evaluate_model(lr_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a882dc3",
   "metadata": {},
   "source": [
    "###  `Random Forest` – Tìm siêu tham số tối ưu - numTrees, maxDepth, maxBins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Random Forest parameters:\n",
      "  numTrees = 100\n",
      "  maxDepth = 15\n",
      "  maxBins  = 64\n",
      " Accuracy (Random Forest): 0.9794\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
    "\n",
    "paramGrid_rf = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(rf.numTrees, [35, 50, 75, 100])\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15])\n",
    "    .addGrid(rf.maxBins, [32, 64])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cvModel_rf = cv_rf.fit(train_data)\n",
    "best_rf_model = cvModel_rf.bestModel\n",
    "rf_predictions = best_rf_model.transform(test_data)\n",
    "\n",
    "print(\" Best Random Forest parameters:\")\n",
    "print(f\"  numTrees = {best_rf_model.getNumTrees}\")\n",
    "print(f\"  maxDepth = {best_rf_model.getOrDefault('maxDepth')}\")\n",
    "print(f\"  maxBins  = {best_rf_model.getOrDefault('maxBins')}\")\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(f\" Accuracy (Random Forest): {rf_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e3608",
   "metadata": {},
   "source": [
    "### `Logistic Regression` – Tìm siêu tham số tối ưu - regParam, elasticNetParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24e2c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Logistic Regression parameters:\n",
      "  regParam = 0.001\n",
      "  elasticNetParam = 1.0\n",
      " Accuracy (Logistic Regression): 0.9950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=1000)\n",
    "\n",
    "paramGrid_lr = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.001, 0.1, 0.3, 0.5, 1.0])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])  # 0=L2, 1=L1\n",
    "    .build()\n",
    ")\n",
    "\n",
    "cv_lr = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid_lr,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cvModel_lr = cv_lr.fit(train_data)\n",
    "best_lr_model = cvModel_lr.bestModel\n",
    "lr_predictions = best_lr_model.transform(test_data)\n",
    "\n",
    "print(\" Best Logistic Regression parameters:\")\n",
    "print(f\"  regParam = {best_lr_model.getRegParam()}\")\n",
    "print(f\"  elasticNetParam = {best_lr_model.getElasticNetParam()}\")\n",
    "\n",
    "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
    "print(f\" Accuracy (Logistic Regression): {lr_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48af7c",
   "metadata": {},
   "source": [
    "### Tìm mô hình tốt nhất (kèm theo tham số tối ưu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99d873d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " So sánh mô hình:\n",
      "   Random Forest: Accuracy = 0.9794\n",
      "     numTrees: 100\n",
      "     maxDepth: 15\n",
      "     maxBins: 64\n",
      "--------------------------------------------------\n",
      " Logistic Regression: Accuracy = 0.9950\n",
      "     regParam: 0.001\n",
      "     elasticNetParam: 1.0\n",
      "--------------------------------------------------\n",
      "\n",
      " Mô hình tốt nhất: Logistic Regression (Độ chính xác = 0.9950)\n",
      "  Siêu tham số tối ưu:\n",
      "   regParam: 0.001\n",
      "   elasticNetParam: 1.0\n"
     ]
    }
   ],
   "source": [
    "import builtins  # dùng max gốc của Python\n",
    "\n",
    "models_info = [\n",
    "    {\n",
    "        \"name\": \"Random Forest\",\n",
    "        \"accuracy\": rf_accuracy,\n",
    "        \"params\": {\n",
    "            \"numTrees\": best_rf_model.getNumTrees,\n",
    "            \"maxDepth\": best_rf_model.getOrDefault(\"maxDepth\"),\n",
    "            \"maxBins\": best_rf_model.getOrDefault(\"maxBins\")\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Logistic Regression\",\n",
    "        \"accuracy\": lr_accuracy,\n",
    "        \"params\": {\n",
    "            \"regParam\": best_lr_model.getRegParam(),\n",
    "            \"elasticNetParam\": best_lr_model.getElasticNetParam()\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dùng builtins.max \n",
    "best_model = builtins.max(models_info, key=lambda m: m[\"accuracy\"])\n",
    "\n",
    "print(\"\\n So sánh mô hình:\")\n",
    "for m in models_info:\n",
    "    marker = \"\" if m[\"name\"] == best_model[\"name\"] else \"  \"\n",
    "    print(f\"{marker} {m['name']}: Accuracy = {m['accuracy']:.4f}\")\n",
    "    for k, v in m[\"params\"].items():\n",
    "        print(f\"     {k}: {v}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\n Mô hình tốt nhất: {best_model['name']} (Độ chính xác = {best_model['accuracy']:.4f})\")\n",
    "print(\"  Siêu tham số tối ưu:\")\n",
    "for k, v in best_model[\"params\"].items():\n",
    "    print(f\"   {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "922478b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dự đoán 10 mẫu ngẫu nhiên bằng mô hình tốt nhất: Logistic Regression\n",
      "+-------------------------------------+-------------------------------------+----------+------+-------+--------+------+-------+--------+----------+\n",
      "|city1                                |city2                                |passengers|fare  |nsmiles|large_ms|lf_ms |fare_lg|fare_low|Phân_Loại |\n",
      "+-------------------------------------+-------------------------------------+----------+------+-------+--------+------+-------+--------+----------+\n",
      "|Chicago, IL                          |Portland, ME                         |141       |340.41|900    |0.6     |0.29  |398.02 |245.22  |Cao       |\n",
      "|Buffalo, NY                          |New York City, NY (Metropolitan Area)|271       |105.92|326    |0.98    |0.98  |105.42 |105.42  |Trung bình|\n",
      "|New York City, NY (Metropolitan Area)|St. Louis, MO                        |478       |291.42|928    |0.81    |0.01  |303.0  |163.91  |Cao       |\n",
      "|Houston, TX                          |Memphis, TN                          |278       |231.65|484    |0.8692  |0.0178|228.47 |210.93  |Cao       |\n",
      "|San Francisco, CA (Metropolitan Area)|Seattle, WA                          |2206      |115.75|696    |0.36    |0.25  |116.28 |99.78   |Cao       |\n",
      "|Louisville, KY                       |Tampa, FL (Metropolitan Area)        |324       |140.47|727    |0.69    |0.69  |135.83 |135.83  |Cao       |\n",
      "|Albany, NY                           |Chicago, IL                          |297       |189.73|723    |0.76    |0.13  |188.96 |182.43  |Cao       |\n",
      "|Jacksonville, FL                     |Norfolk, VA (Metropolitan Area)      |140       |116.08|547    |0.64    |0.27  |124.24 |95.69   |Cao       |\n",
      "|San Francisco, CA (Metropolitan Area)|West Palm Beach/Palm Beach, FL       |96        |328.0 |2567   |0.53    |0.1   |345.65 |254.9   |Trung bình|\n",
      "|Boston, MA (Metropolitan Area)       |Raleigh/Durham, NC                   |134       |173.11|625    |0.4357  |0.1859|184.66 |72.39   |Cao       |\n",
      "+-------------------------------------+-------------------------------------+----------+------+-------+--------+------+-------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col, rand\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Ánh xạ nhãn số sang tên (theo thứ tự StringIndexer đã huấn luyện)\n",
    "label_mapping = {0.0: \"Cao\", 1.0: \"Trung bình\", 2.0: \"Thấp\"}\n",
    "map_label_udf = udf(lambda x: label_mapping.get(x, \"Không rõ\"), StringType())\n",
    "\n",
    "# Lấy 10 mẫu ngẫu nhiên từ tập test\n",
    "sample_test = test_data.orderBy(rand()).limit(10)\n",
    "\n",
    "# Xác định mô hình tốt nhất\n",
    "if best_model[\"name\"] == \"Random Forest\":\n",
    "    best_model_object = best_rf_model\n",
    "elif best_model[\"name\"] == \"Logistic Regression\":\n",
    "    best_model_object = best_lr_model\n",
    "else:\n",
    "    raise ValueError(\"Không xác định được mô hình tốt nhất!\")\n",
    "\n",
    "# Dự đoán\n",
    "sample_predictions = best_model_object.transform(sample_test)\n",
    "\n",
    "# Thêm nhãn thật và dự đoán dạng chữ\n",
    "sample_with_labels = (\n",
    "    sample_predictions\n",
    "    .withColumn(\"Phân_Loại\", map_label_udf(col(\"prediction\")))\n",
    ")\n",
    "\n",
    "# Hiển thị các cột chính\n",
    "columns_to_show = [\n",
    "    \"city1\", \"city2\", \"passengers\", \"fare\", \"nsmiles\",\n",
    "    \"large_ms\", \"lf_ms\", \"fare_lg\", \"fare_low\",\"Phân_Loại\"\n",
    "]\n",
    "\n",
    "print(f\"\\n Dự đoán 10 mẫu ngẫu nhiên bằng mô hình tốt nhất: {best_model['name']}\")\n",
    "sample_with_labels.select(columns_to_show).show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
